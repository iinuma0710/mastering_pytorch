{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398bcdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e585b8c",
   "metadata": {},
   "source": [
    "# Tensor モジュール\n",
    "前述したようにテンソルは概念的には NumPy の配列に似ています．テンソルは $n$ 次元の配列で，その上で数学関数を操作したり，GPU を使って計算を高速化したりすることができます．また，テンソルは深層学習に不可欠な計算グラフやグラデーションを追跡するためにも使用できます．GPU でテンソルを実行するためには，テンソルを特定のデータ型にキャストする必要があります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7fe048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テンソルの定義\n",
    "points = torch.tensor([1.0, 4.0, 2.0, 1.0, 3.0, 5.0])\n",
    "\n",
    "# 最初の要素を取得\n",
    "float(points[0])\n",
    "\n",
    "# テンソルの次元 (shape) を確認\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447a190",
   "metadata": {},
   "source": [
    "PyTorch では，テンソルはメモリの連続したチャンクに格納された数値データの1次元配列に対するビューとして実装されています．これらの配列はストレージインスタンス (記憶域インスタンス，storage instance) と呼ばれます．すべての PyTorch テンソルには ```storage``` 属性があり，以下の例のようにテンソルの基礎となるストレージインスタンスを出力することができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e994c5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 4.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f499016",
   "metadata": {},
   "source": [
    "テンソルがストレージインスタンスのビューであるというとき，テンソルはビューを実装するために\n",
    "\n",
    "- Size\n",
    "- Storage\n",
    "- Offset\n",
    "- Stride\n",
    "\n",
    "という4つの情報を使用します．先ほどのテンソルで，これらの情報の意味を調べてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f668d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489f863",
   "metadata": {},
   "source": [
    "このように，```size```は NumPy の ```shape``` 属性と似ており，各次元の要素数を教えてくれます．これらの数値を掛け合わせると，基礎となるストレージインスタンスの長さ (この場合は6) になります．  \n",
    "オフセットは次のようになります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e434ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050cc9f",
   "metadata": {},
   "source": [
    "ここでのオフセットは，記憶域配列 (storage array) 内のテンソルの最初の要素のインデックスを表しています．出力は0なので，テンソルの最初の要素が記憶域配列の最初の要素であることを意味しています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dcb06ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1].storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d0b5c",
   "metadata": {},
   "source": [
    "```points[1]``` は $[2.0, 1.0]$ であり，記憶域配列は $[1.0, 4.0, 2.0, 1.0, 3.0, 5.0]$ なので，テンソル $[2.0, 1.0]$ の最初の要素，すなわち， $2.0$ は記憶配列のインデックス2にあります．\n",
    "最後に ```stride``` を見てみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42d5412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a6535",
   "metadata": {},
   "source": [
    "ここまで見てきた通り，```stride``` には各次元ごとに，テンソルの次の要素にアクセスするために，スキップする要素数が含まれています．つまり，この例では第1の次元において最初の要素（1.0）の次の要素にアクセスするためには，2つの要素（つまり，1.0 と 4.0）を飛ばして，次の要素（2.0）にアクセスする必要があります．同様に，2番目の次元では，1.0 の次の要素，つまり 4.0 にアクセスするために，1つの要素をスキップする必要があります．このように，これらの属性を利用して，連続した1次元の記憶配列からテンソルを導き出すことができます．  \n",
    "テンソルに含まれるデータは数値型で，具体的に PyTorch は以下のデータ型をテンソルに含めることができます．\n",
    "\n",
    "- ```torch.float32``` or ```torch.float``` ：32ビット (単精度) 浮動小数点数\n",
    "- ```torch.float64``` or ```torch.double```：64ビット (倍精度) 浮動小数点数\n",
    "- ```torch.float16``` or ```torch.half```  ：16ビット (半精度) 浮動小数点数  \n",
    "- ```torch.int8``` ：8ビット符号付き整数\n",
    "- ```torch.uint8```：8ビット符号なし整数  \n",
    "- ```torch.int16``` or ```torch.shor```：16ビット符号付き整数  \n",
    "- ```torch.int32``` or ```torch.int``` ：32ビット符号付き整数  \n",
    "- ```torch.int64``` or ```torch.long```：64ビット符号付き整数\n",
    "\n",
    "テンソルに使用するデータ型は次のように指定します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70774fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd62ed6",
   "metadata": {},
   "source": [
    "PyTorch のテンソルには，データ型の他にテンソルを格納するデバイスの指定が必要です．デバイスはインスタンスとして指定できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e330e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4ccf4",
   "metadata": {},
   "source": [
    "あるいは，目的のデバイスにテンソルのコピーを作成することもできます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ecf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_2 = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d08bf",
   "metadata": {},
   "source": [
    "このように，テンソルを CPU に割り当てる（```device='cpu'```を使用）こともできるし，テンソルを GPU に割り当てる（```device='cuda'```を使用）こともできます．GPUにテンソルを配置すると計算を高速化可能で，CPU でも GPU でもほとんど同じテンソル API を利用可能なので，デバイス間でテンソルを移動したり，計算を実行したり，データを書き戻したりが簡単にできるようになっています．  \n",
    "同じ種類のデバイスが複数ある場合，つまり，複数の GPU が使えるときには，次のようにデバイスのインデックスを指定することで，テンソルを配置するデバイスを指定できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f280bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3 = points.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a684f",
   "metadata": {},
   "source": [
    "PyTorch-CUDA について，詳しくは[ここを参照](https://pytorch.org/docs/stable/notes/cuda.html)してください．より一般的な CUDA については，[こちらのページ](https://developer.nvidia.com/about-cuda)が参考になります．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
