# CNN と LSTM の組み合わせ
畳み込みニューラルネットワーク (CNN: Convolutional Neural Network) は，画像分類や物体検出，セグメンテーションなど，画像や映像に関連する機械学習問題の解決で良く知られている深層学習モデルの一種です．
これは，CNN が空間的なレイヤの一種である畳み込み層 (convolutional layer) を使っているからです．
畳み込み層は学習可能なパラメータを共有しています．
重みあるいはパラメータはが共有されるのは，画像内で学習されるエッジや輪郭といったパターンは，画像内でのピクセル位置とは独立であると考えられるからです．  
CNN が画像に適用されるように，LSTM (Long Short-Term Memory) ネットワークは RNN (Recurrent Newural Network) の一種で，連続データに関連する機械学習の課題を解決するのに非常に効果的です．
連続データには例えばテキストがあります．
文章の中では各単語は以前の単語に依存しています．
LSTM モデルは，このような依存関係をモデリングすることを意図しています．

これら2種類のネットワークをつなぎ合わせることで，画像や映像を入力としてテキストを出力するハイブリッドモデルを構築できます．
有名なアプリケーションとしては，画像を入力として，そのもっともらしい説明文を出力するイメージキャプショニング (image captioning) があります．
イメージキャプショニングに機械学習が適用されるようになったのは2010年ごろの話です．  
しかし，この分野でニューラルネットワークが成功を収めるようになったのは2014～2015年になってからでした．
それ以来，イメージキャプショニングは活発に研究されています．
この深層学習アプリケーションは毎年い大幅に性能が向上しており，視覚障害者が世界をよりよく視覚化するのに役立つかもしれません．

本章では，最初に PyTorch での実装の詳細に触れながら，先ほどのハイブリッドモデルのアーキテクチャについて議論し，イメージキャプショニングシステムを1から構築します．
本章では次のような内容を扱います．

- CNN と LSTM をによってニューラルネットワークを構築する
- PyTorch でイメージキャプショニング生成器を構築する

## CNN と LSTM を用いたニューラルネットワークの構築
CNN-LSTM ネットワークアーキテクチャは，入力データ (画像) から特徴量を抽出する畳み込み層と，それに続いて系列の予測を行う LSTM 層から構成されています．
この種のモデルは空間的にも時間的にも深いネットワークになっています．
モデルの畳み込み部分はしばしばエンコーダ (encoder) として利用され，画像を入力として高次元の特徴量や埋め込み (embedding) を出力します．  
実際には，このようなハイブリッドネットワークでは，しばしば画像分類タスクで事前学習済みの CNN が用いられます．
事前学習済み CNN モデルの最後の隠れ層は LSTM の入力となり，テキストを生成するデコーダ (decoder) として作用します．  
テキストデータを扱う場合には，トークンと呼ばれる単語やその他の記号 (句読点や識別子など) を数値に変換する必要があります．
ここでは，テキストに登場する各トークンに対応するユニークな数字で表しています．

### テキストエンコーディングの例
次のような文章を機械学習モデルに入力することを考えます．

```
<start> PyTorch is a deep learning library. <end>
```

これらの各トークンにそれぞれ数値を割り当ててやります．

```
<start> : 0
PyTorch : 1
is : 2
a : 3
deep : 4
learning : 5
library : 6
. : 7
<end> : 8
```

これによって，元の文章を数値のリストで表現できるようになります．

```
<start> PyTorch is a deep learning library. <end> -> [0, 1, 2, 3, 4, 5, 6, 7, 8]
```

同様に ```<start> PyTorch is deep. <end>``` をエンコードすると，```[0, 1, 2, 4, 7, 8]``` となります．
一般的に，このような変換はボキャブラリー (vocabulary) と呼ばれ，ボキャブラリーの構築はほとんどのテキスト関連の機械学習でとても重要です．  
デコーダとして作用する LSTM モデルは，CNN の埋め込みを時刻 0 の入力として受け取ります．
そして，各 LSTM セルは各時刻ごとのトークン予測を行い，それを次の LSTM セルの入力とします．
したがって，全体のアーキテクチャは次の図のようになります．

<div align="center">
    <image src="../../images/cnn_lstm.png" width="640" />
</div>

このようなアーキテクチャはイメージキャプショニングタスクに最適です．
1枚の画像の代わりに画像系列，つまり映像を CNN 層の入力とした場合，時刻 0 以外の各時刻における LSTM セルの入力として CNN の埋め込みを含めてしまいます．
このようなアーキテクチャは，動作認識や映像説明のようなアプリケーションに有用です．  
次節では，ハイブリッドモデルアーキテクチャの構築に加えて，データの読み込みや前処理，モデルの学習と評価のパイプラインを含む，PyTorch による画像キャプションシステムの実装をみていきます．

## PyTorch を用いた画像キャプション生成の構築
ここでは，大規模な物体検出，セグメンテーション，キャプショニング向けの [COCO (Common Objects COntext) データセット](http://cocodataset.org/#overview)を使います．
このデータセットは5つのキャプションが付与された20万枚以上のラベル付き画像で構成されています．
COCO データセットは2014年に発表されて以降，物体認識関連の CV 系タスクの進歩に大きく貢献してきました．
物体検出や物体のセグメンテーション，インスタンスセグメンテーション，イメージキャプショニングなどのタスクにおいて最もよく使われるデータセットです．  
CNN-LSTM モデルの構築と学習を行う前に，いくつか準備が必要です．

これ以降は [Jupyter Notebook]() 参照．